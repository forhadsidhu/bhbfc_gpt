# ğŸ“š RAG Based Chatbot R&D for BD Govt Organization

This is a **Retrieval-Augmented Generation (RAG) Chatbot** built with **Pinecone for vector search**, **local embeddings using Sentence Transformers**, and **Llama as the LLM**. The chatbot retrieves relevant context from a document store and generates responses using a local Llama model. I am doing R&D on different models for CPU inference and better accuracy.

---

## ğŸ–¼ï¸ Demo
![Chatbot Demo](demo.png)

---

## ğŸš€ Features

- **Retrieval-Augmented Generation (RAG)**: Retrieves relevant documents from Pinecone before generating responses.
- **Local Embeddings**: Uses `sentence-transformers` instead of OpenAI embeddings.
- **Llama Model for Chat Completion**: Runs a local Llama model for response generation.
- **Streamlit UI**: Interactive chat interface built with Streamlit.

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/forhadsidhu/bhbfc_gpt
cd BHBFC_chatbot
```

### 2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)
```sh
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables
Create a **`.env`** file in the project root and add your Pinecone API key:
```env
PINECONE_API_KEY=your_pinecone_api_key
```

---

## ğŸ›  Configuration

### ğŸ”¹ Pinecone Index
Ensure your Pinecone index has the **correct dimensions** matching your embedding model:
- `all-MiniLM-L6-v2` â†’ **384 dimensions**
- `all-mpnet-base-v2` â†’ **768 dimensions**

If you need to create a new index:
```python
from pinecone import Pinecone

pc = Pinecone(api_key="your_pinecone_api_key")
pc.create_index(name="langchain-demo", dimension=768, metric="cosine")
```

### ğŸ”¹ Change Embedding Model (If Needed)
By default, the chatbot uses:
```python
embedding_model = SentenceTransformer("all-mpnet-base-v2")  # 768 dimensions
```
If your Pinecone index uses a different dimension, change the model accordingly.

---

## â–¶ï¸ Running the Chatbot

### **Start the Streamlit App**
```sh
streamlit run app.py
```
This will open a web UI where you can chat with the bot.

---

## ğŸ— Project Structure
```
ğŸ“‚ rag-chatbot
 â”œâ”€â”€ ğŸ“„ app.py             # Main Streamlit app
 â”œâ”€â”€ ğŸ“„ requirements.txt   # Required Python dependencies
 â”œâ”€â”€ ğŸ“„ .env               # Pinecone API key (Not included in the repo)
 â”œâ”€â”€ ğŸ“‚ models/            # Directory for storing the Llama model
 â”œâ”€â”€ ğŸ“‚ data/              # Store any preprocessed documents (if needed)
 â”œâ”€â”€ ğŸ“„ demo.png           # Screenshot of the chatbot UI
 â”œâ”€â”€ ğŸ“„ README.md          # Project documentation
```


## ğŸ›  Troubleshooting

### **Vector Dimension Mismatch Error**
âŒ `Vector dimension 384 does not match the dimension of the index 768`
- **Solution:** Ensure your embedding model and Pinecone index dimensions match.
- **Fix:** Use `all-mpnet-base-v2` for 768-dimension or recreate the Pinecone index with 384 dimensions.

### **Pinecone API Key Error**
âŒ `Missing Pinecone API key! Check your .env file.`
- **Solution:** Ensure you have added your Pinecone API key in the `.env` file.

---

## ğŸ”— Resources

- [Pinecone Docs](https://docs.pinecone.io/)
- [Sentence Transformers](https://www.sbert.net/)
- [Llama.cpp](https://github.com/ggerganov/llama.cpp)

---

## ğŸ“ License

This project is licensed under the MIT License.

